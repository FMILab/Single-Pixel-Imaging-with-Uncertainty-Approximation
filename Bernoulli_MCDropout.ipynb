{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU memory, clear and recheck\n",
    "from numba import cuda\n",
    "gpu = cuda.select_device(0)\n",
    "print('Selected GPU is:', gpu)\n",
    "memory = cuda.current_context().get_memory_info()\n",
    "print('Memory Status:', memory[0], 'free out of', memory[1], ',', (int(memory[0])/int(memory[1])*100), '% free')\n",
    "\n",
    "print('Clearing Memory...')\n",
    "gpu = cuda.select_device(0)\n",
    "gpu.reset()\n",
    "memory = cuda.current_context().get_memory_info()\n",
    "print('Memory Status:', memory[0], 'free out of', memory[1], ',', (int(memory[0])/int(memory[1])*100), '% free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import scipy as sp\n",
    "import scipy.io as spio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from random import randint, uniform, gauss\n",
    "from math import sqrt\n",
    "from tqdm import tqdm_notebook, tqdm, tnrange\n",
    "from pathlib import Path\n",
    "from pylab import figure, cm\n",
    "from tensorflow import keras\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Checking the system is up to date and GPU is enabled\n",
    "import sys\n",
    "print(sys.executable)\n",
    "print(tf.__version__)\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model or create one from scratch\n",
    "model_path = \"BCNN_model.h5\"\n",
    "weights_path = \"BCNN_weights.hdf5\"\n",
    "saved_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data (x is the network input, y is the ground-truth)\n",
    "n = 1000\n",
    "x = sp.ndarray((n,32,32,1))\n",
    "y = sp.ndarray((n,32,32,1))\n",
    "\n",
    "mat_dict = sp.io.loadmat(\"./ground_truth.mat\")\n",
    "y[:,:,:,0] = mat_dict[\"x\"]\n",
    "mat_dict = sp.io.loadmat(\"./network_input.mat\")\n",
    "x[:,:,:,0]= mat_dict[\"Y_image\"]\n",
    "\n",
    "# 800 images for training, 100 images for validating, and 100 images for testing    \n",
    "x_train = x[0:800,:,:,:]\n",
    "y_train = y[0:800,:,:,:]\n",
    "x_validate = x[800:900,:,:,:]\n",
    "y_validate = y[800:900,:,:,:]\n",
    "x_test = x[900:1000,:,:,:]\n",
    "y_test = y[900:1000,:,:,:]\n",
    "print('x_train shape is ', x_train.shape)\n",
    "print('y_train shape is ', y_train.shape)\n",
    "print('x_validate shape is ', x_validate.shape)\n",
    "print('y_validate shape is ', y_validate.shape)\n",
    "print('x_test shape is ', x_test.shape)\n",
    "print('y_test shape is ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss functions\n",
    "import keras_contrib as kc\n",
    "from keras_contrib.losses import DSSIMObjective\n",
    "ssObj = DSSIMObjective(k1=0.01, k2=0.03, kernel_size=3, max_value=1.0)\n",
    "def DSSIM_LOSS(y_true,y_pred):\n",
    "    mask_true = y_true[:,:,:,0]\n",
    "    mask_true1 = mask_true[:,:,:,tf.newaxis]\n",
    "    mask_pred = y_pred[:,:,:,0]\n",
    "    mask_pred1= mask_pred[:,:,:,tf.newaxis]\n",
    "    return ssObj(mask_true1,mask_pred1)\n",
    "\n",
    "def RMSE_LOSS(y_true, y_pred):\n",
    "    mask_true = y_true[:, :, :, 0]\n",
    "   #mask_pred = y_pred[:, :, :, 2]\n",
    "    mask_pred = y_pred[:,:,:,0]\n",
    "    loss_1 = K.sqrt(K.mean(K.square(mask_true - mask_pred)))\n",
    "    return loss_1\n",
    "\n",
    "def mae_loss(y_true, y_pred):\n",
    "    mask_true = y_true[:, :, :, 0]\n",
    "    mask_pred = y_pred[:,:,:,0]\n",
    "    loss_2 = (K.abs(mask_true - mask_pred))\n",
    "    return loss_2\n",
    "\n",
    "def bernoulli_loss(y_true, y_pred):\n",
    "    mask_true = y_true[:,:,:,0]\n",
    "    mask_pred = y_pred[:,:,:,0]\n",
    "    loss_3 = K.mean(tf.multiply(mask_true-1,K.log(1-mask_pred + 1e-9)) - tf.multiply(mask_true,K.log(mask_pred + 1e-9)))\n",
    "    return loss_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the network and load the trained weights\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Input, Activation\n",
    "from keras.layers.core import Dropout, Lambda, Dense, Reshape, Permute\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "if not saved_model:\n",
    "    inputs = Input((32,32,1))\n",
    "\n",
    "    c1 = Conv2D(1, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (inputs)\n",
    "    c1 = Dropout(0.1) (c1,training=True)\n",
    "    #c1 = Dense(16) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Dropout(0.1) (p1,training=True)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c2)\n",
    "    c2 = Dropout(0.1) (c2,training=True)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Dropout(0.1) (p2,training=True)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c3)\n",
    "    c3 = Dropout(0.1) (c3,training=True)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Dropout(0.1) (p3,training=True)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c4)\n",
    "    c4 = Dropout(0.1) (c4,training=True)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Dropout(0.1) (p4,training=True)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c5)\n",
    "    c5 = Dropout(0.1) (c5,training=True)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Dropout(0.1) (u6,training=True)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c6)\n",
    "    c6 = Dropout(0.1) (c6,training=True)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Dropout(0.1) (u7,training=True)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c7)\n",
    "    c7 = Dropout(0.1) (c7,training=True)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Dropout(0.1) (u8,training=True)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c8)\n",
    "    c8 = Dropout(0.1) (c8,training=True)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Dropout(0.1) (u9,training=True)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c9)\n",
    "    c9 = Dropout(0.1) (c9,training=True)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c9)\n",
    "    \n",
    "    outputs = Conv2D(1, (3, 3), activation='sigmoid',kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c9)\n",
    "\n",
    "    BCNN_bernoulli_train1 = Model(inputs=[inputs], outputs=[outputs])\n",
    "    BCNN_bernoulli_train1.load_weights(weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with Monte Carlo Dropouts, and measure how much time it takes\n",
    "num_dropout_ensembles = 16 # number of Monte Carlo Dropouts\n",
    "prediction_ensembles = sp.ndarray((100,32,32,1,num_dropout_ensembles))\n",
    "predict_start = time.time()\n",
    "for dropout_idx in range(num_dropout_ensembles):\n",
    "    prediction = BCNN_bernoulli_train1.predict(x_test)\n",
    "    prediction_ensembles[:,:,:,:,dropout_idx] = prediction\n",
    "predict_end = time.time()\n",
    "print('Predicting: time elapsed is', (predict_end - predict_start))\n",
    "print('Average prediction time was', (predict_end-predict_start)/(100*num_dropout_ensembles)*1000, 'milliseconds per image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predicted image and uncertainty\n",
    "prediction_result = sp.ndarray((100,32,32,2))\n",
    "for i in range(100):\n",
    "    prediction_result[i, :, :, 0] = np.mean(prediction_ensembles[i, :, :, 0, :].squeeze(), axis=2)\n",
    "    prediction_result[i, :, :, 1] = np.sqrt((np.mean((np.multiply(prediction_ensembles[i, :, :, 0, :],1-prediction_ensembles[i, :, :, 0, :])).squeeze(), axis=2)) ** 2 +\n",
    "                                         (np.std(prediction_ensembles[i, :, :, 0, :].squeeze(), axis=2)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import axis as ax\n",
    "# Visualize a random testing image\n",
    "test_index = randint(0,100)\n",
    "print('test index of ',test_index)\n",
    "\n",
    "\n",
    "inputimage = x_test[test_index,:,:,0] # network input\n",
    "truth = y_test[test_index,:,:,0] # ground truth\n",
    "output1 = prediction_result[test_index,:,:,0] # predicted image\n",
    "output2 = prediction_result[test_index,:,:,1] # predicted uncertainty\n",
    "\n",
    "\n",
    "im1 = plt.matshow(truth, cmap=cm.gray,vmin = 0.0, vmax = 1.0)\n",
    "cbar1 = plt.colorbar(im1)\n",
    "plt.gca().xaxis.tick_bottom()\n",
    "plt.title(r'Ground Truth')\n",
    "\n",
    "im2 = plt.matshow(output1, cmap=cm.gray,vmin = 0.0, vmax = 1.0)\n",
    "cbar2 = plt.colorbar(im2)\n",
    "plt.gca().xaxis.tick_bottom()\n",
    "plt.title(r'Predicted Image')\n",
    "\n",
    "im3 = plt.matshow(output2, cmap=cm.jet,vmin = 0.0, vmax = 1.0)\n",
    "cbar3 = plt.colorbar(im3)\n",
    "plt.gca().xaxis.tick_bottom()\n",
    "plt.title(r'Predicted Uncertainty')\n",
    "\n",
    "im4 = plt.matshow(abs(truth-output1), cmap=cm.jet,vmin = 0.0, vmax = 1.0)\n",
    "cbar4 = plt.colorbar(im4)\n",
    "plt.gca().xaxis.tick_bottom()\n",
    "plt.title(r'True Absolute Error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "Image_BCNN2 = prediction_result\n",
    "Image_MCDropout = prediction_ensembles\n",
    "sio.savemat('Image_BCNN2.mat',{'Image_BCNN2':Image_BCNN2})\n",
    "sio.savemat('Image_MCDropout.mat',{'Image_MCDropout':Image_MCDropout})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
