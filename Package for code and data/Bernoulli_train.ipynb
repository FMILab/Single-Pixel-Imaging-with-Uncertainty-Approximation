{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU memory, clear and recheck\n",
    "from numba import cuda\n",
    "gpu = cuda.select_device(0)\n",
    "print('Selected GPU is:', gpu)\n",
    "memory = cuda.current_context().get_memory_info()\n",
    "print('Memory Status:', memory[0], 'free out of', memory[1], ',', (int(memory[0])/int(memory[1])*100), '% free')\n",
    "\n",
    "print('Clearing Memory...')\n",
    "gpu = cuda.select_device(0)\n",
    "gpu.reset()\n",
    "memory = cuda.current_context().get_memory_info()\n",
    "print('Memory Status:', memory[0], 'free out of', memory[1], ',', (int(memory[0])/int(memory[1])*100), '% free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import scipy as sp\n",
    "import scipy.io as spio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from random import randint, uniform, gauss\n",
    "from math import sqrt\n",
    "from tqdm import tqdm_notebook, tqdm, tnrange\n",
    "from pathlib import Path\n",
    "from pylab import figure, cm\n",
    "from tensorflow import keras\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Checking the system is up to date and GPU is enabled\n",
    "import sys\n",
    "print(sys.executable)\n",
    "print(tf.__version__)\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model or create one from scratch\n",
    "model_path = \"BCNN_model.h5\"\n",
    "weights_path = \"BCNN_weights.hdf5\"\n",
    "saved_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data (x is the network input, y is the ground-truth)\n",
    "n = 1000\n",
    "x = sp.ndarray((n,32,32,1))\n",
    "y = sp.ndarray((n,32,32,1))\n",
    "\n",
    "mat_dict = sp.io.loadmat(\"./ground_truth.mat\")\n",
    "y[:,:,:,0] = mat_dict[\"x\"]\n",
    "mat_dict = sp.io.loadmat(\"./network_input.mat\")\n",
    "x[:,:,:,0]= mat_dict[\"Y_image\"]\n",
    "\n",
    "# 800 images for training, 100 images for validating, and 100 images for testing\n",
    "x_train = x[0:800,:,:,:]\n",
    "y_train = y[0:800,:,:,:]\n",
    "x_validate = x[800:900,:,:,:]\n",
    "y_validate = y[800:900,:,:,:]\n",
    "x_test = x[900:1000,:,:,:]\n",
    "y_test = y[900:1000,:,:,:]\n",
    "print('x_train shape is ', x_train.shape)\n",
    "print('y_train shape is ', y_train.shape)\n",
    "print('x_validate shape is ', x_validate.shape)\n",
    "print('y_validate shape is ', y_validate.shape)\n",
    "print('x_test shape is ', x_test.shape)\n",
    "print('y_test shape is ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss functions\n",
    "import keras_contrib as kc\n",
    "from keras_contrib.losses import DSSIMObjective\n",
    "ssObj = DSSIMObjective(k1=0.01, k2=0.03, kernel_size=3, max_value=1.0)\n",
    "def DSSIM_LOSS(y_true,y_pred):\n",
    "    mask_true = y_true[:,:,:,0]\n",
    "    mask_true1 = mask_true[:,:,:,tf.newaxis]\n",
    "    mask_pred = y_pred[:,:,:,0]\n",
    "    mask_pred1= mask_pred[:,:,:,tf.newaxis]\n",
    "    return ssObj(mask_true1,mask_pred1)\n",
    "\n",
    "def RMSE_LOSS(y_true, y_pred):\n",
    "    mask_true = y_true[:, :, :, 0]\n",
    "   #mask_pred = y_pred[:, :, :, 2]\n",
    "    mask_pred = y_pred[:,:,:,0]\n",
    "    loss_1 = K.sqrt(K.mean(K.square(mask_true - mask_pred)))\n",
    "    return loss_1\n",
    "\n",
    "def mae_loss(y_true, y_pred):\n",
    "    mask_true = y_true[:, :, :, 0]\n",
    "    mask_pred = y_pred[:,:,:,0]\n",
    "    loss_2 = (K.abs(mask_true - mask_pred))\n",
    "    return loss_2\n",
    "\n",
    "def bernoulli_loss(y_true, y_pred):\n",
    "    mask_true = y_true[:,:,:,0]\n",
    "    mask_pred = y_pred[:,:,:,0]\n",
    "    loss_3 = K.mean(tf.multiply(mask_true-1,K.log(1-mask_pred + 1e-9)) - tf.multiply(mask_true,K.log(mask_pred + 1e-9)))\n",
    "    return loss_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct and compile the network\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Input, Activation\n",
    "from keras.layers.core import Dropout, Lambda, Dense, Reshape, Permute\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "if not saved_model:\n",
    "    inputs = Input((32,32,1))\n",
    "\n",
    "    c1 = Conv2D(1, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (inputs)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    #c1 = Dense(16) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Dropout(0.1) (p1)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c2)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Dropout(0.1) (p2)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c3)\n",
    "    c3 = Dropout(0.1) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Dropout(0.1) (p3)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c4)\n",
    "    c4 = Dropout(0.1) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Dropout(0.1) (p4)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c5)\n",
    "    c5 = Dropout(0.1) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Dropout(0.1) (u6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c6)\n",
    "    c6 = Dropout(0.1) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Dropout(0.1) (u7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c7)\n",
    "    c7 = Dropout(0.1) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Dropout(0.1) (u8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Dropout(0.1) (u9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c9)\n",
    "    \n",
    "    outputs = Conv2D(1, (3, 3), activation='sigmoid',kernel_initializer='he_normal', kernel_regularizer=l2(1e-6), bias_regularizer=l2(1e-6), padding='same') (c9)\n",
    "\n",
    "\n",
    "    BCNN_bernoulli_train = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    adm = optimizers.adam(lr=0.0005,decay = (1./0.01-1)/20/500)\n",
    "    BCNN_bernoulli_train.compile(optimizer=adm, loss=bernoulli_loss)\n",
    "        \n",
    "BCNN_bernoulli_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the network, and measure the training time\n",
    "if not saved_model:\n",
    "\n",
    "    train_start = time.time()\n",
    "    results = BCNN_bernoulli_train.fit(x_train, y_train, validation_data=(x_validate, y_validate),\n",
    "                               batch_size=40, epochs=500,verbose=1)  \n",
    "    train_end = time.time()\n",
    "    print('Training: time elapsed is', (train_end - train_start))\n",
    "\n",
    "final_loss = BCNN_bernoulli_train.evaluate(x_test, y_test, batch_size=1)\n",
    "print('final loss metric is', final_loss)\n",
    "\n",
    "if not saved_model:\n",
    "    BCNN_bernoulli_train.save(model_path)\n",
    "    BCNN_bernoulli_train.save_weights(weights_path)\n",
    "    print(\"Saved model:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on testing data, and measure how much time it takes\n",
    "predict_start = time.time()\n",
    "prediction = BCNN_bernoulli_train.predict(x_test)\n",
    "predict_end = time.time()\n",
    "print('Predicting: time elapsed is', (predict_end - predict_start))\n",
    "print('Average prediction time was', (predict_end-predict_start)/100*1000, 'milliseconds per image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import axis as ax\n",
    "# Visualize a random testing image\n",
    "test_index = randint(0,100)\n",
    "print('test index of ',test_index)\n",
    "\n",
    "inputimage = x_test[test_index,:,:,0] # network input\n",
    "truth = y_test[test_index,:,:,0] # ground truth\n",
    "output = prediction[test_index,:,:,0] # network prediction\n",
    "\n",
    "\n",
    "\n",
    "im1 = plt.matshow(truth, cmap=cm.gray,vmin = 0.0, vmax = 1.0)\n",
    "cbar1 = plt.colorbar(im1)\n",
    "plt.gca().xaxis.tick_bottom()\n",
    "plt.title(r'Ground Truth')\n",
    "\n",
    "im2 = plt.matshow(output, cmap=cm.gray,vmin = 0.0, vmax = 1.0)\n",
    "cbar2 = plt.colorbar(im2)\n",
    "plt.gca().xaxis.tick_bottom()\n",
    "plt.title(r'Predicted Image')\n",
    "\n",
    "\n",
    "im3 = plt.matshow(abs(truth-output), cmap=cm.jet,vmin = 0.0, vmax = 1.0)\n",
    "cbar3 = plt.colorbar(im3)\n",
    "plt.gca().xaxis.tick_bottom()\n",
    "plt.title(r'True Absolute Error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "Image_BCNN1 = prediction\n",
    "sio.savemat('Image_BCNN1.mat',{'Image_BCNN1':Image_BCNN1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "LOSS_whole = np.asarray(results.history['loss'])\n",
    "LOSS_val_whole = np.asarray(results.history['val_loss'])\n",
    "sio.savemat('LOSS_BCNN1.mat',{'LOSS_whole':LOSS_whole})\n",
    "sio.savemat('LOSS_val_BCNN1.mat',{'LOSS_val_whole':LOSS_val_whole})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
